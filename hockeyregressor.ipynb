{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hockeyregressor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Et7-vDIx1T"
      },
      "source": [
        "!pip install category_encoders --quiet\n",
        "!pip install pdpbox --quiet\n",
        "!pip install scikit-garden --quiet"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quz81nIaI48S"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.inspection import permutation_importance\n",
        "from xgboost import XGBRegressor \n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_poisson_deviance\n",
        "from skgarden.quantile import RandomForestQuantileRegressor\n",
        "\n",
        "\n",
        "URL = 'https://raw.githubusercontent.com/yaobviously/DataCup2021/main/modifiedohl.csv'\n",
        "shots_next_ten = pd.read_csv('https://raw.githubusercontent.com/yaobviously/DataCup2021/main/shotsnext10.csv',\n",
        "                             index_col = 'game_date')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-ruKCYD0jE9"
      },
      "source": [
        "def wrangle(URL):\n",
        "  df = pd.read_csv(URL,\n",
        "                   parse_dates = ['game_date'],\n",
        "                   index_col = 'game_date')\n",
        "  \n",
        "  # dropping columns i made awhile ago that i don't need to build models, \n",
        "  # although they may be handy for communicating insights. all of the score\n",
        "  # and player differentials can now, i see, be reduced to single columns for\n",
        "  # the purposes of model building\n",
        "\n",
        "  col_drop = ['Unnamed: 0', 'possSet', 'shots_next_ten', 'goal_next_ten', \n",
        "              '5on5', '5on4home', '5on3home', '5on4away', '5on3away', \n",
        "              '4on4', 'tie', 'home_ahead_1', 'home_ahead_2', 'home_ahead_3ormore',\n",
        "              'away_ahead_1', 'away_ahead_2', 'away_ahead_3ormore', 'home_team',\n",
        "              'away_team', 'x_coordinate_2', 'y_coordinate_2', 'is_shot', 'player_2']\n",
        "\n",
        "  df = df.drop(columns = col_drop).copy()\n",
        "  df = df.rename(columns = {'detail_3' : 'traffic', 'detail_4' : 'one_timer',\n",
        "                            'detail_1' : 'shot_type', 'detail_2' : 'shot_result'})\n",
        "  \n",
        "  # condensing the above columns\n",
        "\n",
        "  df['home_skater_adv'] = df['home_team_skaters'] - df['away_team_skaters']\n",
        "  df['home_score_diff'] = df['home_team_goals'] - df['away_team_goals']\n",
        "  df['is_shot'] = [1 if event in ['Goal', 'Shot'] else 0 for event in df['event']]\n",
        "\n",
        "  # converting the clock column to the seconds remaining in the period in the\n",
        "  # ugliest way imaginable\n",
        "  \n",
        "  df['min'] = df.clock.apply(lambda x: datetime.datetime.strptime(x,'%M:%S')).dt.minute\n",
        "  df['sec'] = df.clock.apply(lambda x: datetime.datetime.strptime(x, '%M:%S')).dt.second\n",
        "  df['period_sec_rem'] = df['min'] * 60 + df['sec']\n",
        "  \n",
        "  df.drop(columns = 'clock', inplace = True)\n",
        "\n",
        "  # calculating the seconds remaining in the game, mostly for practice (needed!)\n",
        "\n",
        "  def gamesecs(x):\n",
        "  \n",
        "    if x['period'] == 1:\n",
        "      return x['period_sec_rem'] + 2400\n",
        "\n",
        "    if x['period'] == 2:\n",
        "      return x['period_sec_rem'] + 1200\n",
        "  \n",
        "    else:\n",
        "      return x['period_sec_rem']\n",
        "\n",
        "  df['game_sec_rem'] = df.apply(gamesecs, axis = 1)\n",
        "\n",
        "  # creating new columns that contain info on prior game states\n",
        "\n",
        "  df['x_coordinate_1back'] = df['x_coordinate'].shift()\n",
        "  df['y_coordinate_1back'] = df['y_coordinate'].shift()\n",
        "  df['x_coordinate_2back'] = df['x_coordinate'].shift(2)\n",
        "  df['y_coordinate_2back'] = df['y_coordinate'].shift(2)\n",
        "  df['event_1back'] = df['event'].shift()\n",
        "  df['event_2back'] = df['event'].shift(2)\n",
        "\n",
        "  df['sec_last_event'] = np.abs(df.groupby(['gameid', 'period'])['period_sec_rem'].diff())\n",
        "  df['sec_2ndlast_event'] = np.abs(df.groupby(['gameid', 'period'])['period_sec_rem'].diff(2))\n",
        "\n",
        "  # dropping redundant and leaky columns. note 'event' may be useful for\n",
        "  # finding and creating useful (and non-leaky) features\n",
        "  \n",
        "  df.drop(columns = ['min', 'sec', 'is_shot'], inplace = True)\n",
        "\n",
        "  # dropping columns with negligible importance. note 'team' & 'period may be \n",
        "  # useful for finding and creating useful (and non-leaky) features.\n",
        "\n",
        "  lowimp_columns = ['away_team_goals', 'home_team_goals', \n",
        "                    'player', 'home_team_skaters',\n",
        "                    'away_team_skaters', 'traffic', 'gameid', 'period', 'team',\n",
        "                    'one_timer', 'is_goal', 'period_sec_rem']\n",
        "\n",
        "  \n",
        "\n",
        "  df.drop(lowimp_columns, axis = 1, inplace = True)\n",
        "\n",
        "  # I used the below code to create a column counting the shots in the next 10\n",
        "  # seconds of gameplay. because it takes so long to run, i decided to save it directly\n",
        "  # to a new .csv file\n",
        "  \n",
        "  # sums = []\n",
        "  # for game, period, sec in zip(df['gameid'], df['period'], df['period_sec_rem']):\n",
        "    \n",
        "  # sec_plus_10 = sec - 10  \n",
        "  # mask = ((df['gameid'] == game) & \\\n",
        "  # (df['period'] == period) & \\\n",
        "  # (df['period_sec_rem'] >= sec_plus_10) & \\\n",
        "  # (df['period_sec_rem'] < sec))\n",
        "  # sum_shots = df.loc[mask]['is_shot'].sum()\n",
        "  # sums.append(sum_shots)\n",
        "\n",
        "  # adding the shots column\n",
        "  df['shots_next_ten'] = shots_next_ten['shots_next_10']\n",
        "  \n",
        "\n",
        "  return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtN_kBHAJz7w"
      },
      "source": [
        "df = wrangle(URL)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_M9GbhTKM_F"
      },
      "source": [
        "target = 'shots_next_ten'\n",
        "\n",
        "train_threshold = '2020-01-15'\n",
        "test_threshold = '2020-02-13'\n",
        "\n",
        "mask = df.index < train_threshold\n",
        "mask2 = df.index > test_threshold\n",
        "\n",
        "X = df.drop(target, axis = 1)\n",
        "y = df[target]\n",
        "\n",
        "X_train, y_train = X[mask], y[mask]\n",
        "X_val, y_val = X[~mask & ~mask2], y[~mask & ~mask2]\n",
        "X_test, y_test = X[mask2], y[mask2]"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At4QAxYnM9wu",
        "outputId": "3acc1013-1817-433f-8e45-a6cbb148755a"
      },
      "source": [
        "naive_pred_train = [y_train.mean()] * len(y_train)\n",
        "baseline_MAE_train = mean_absolute_error(y_train, naive_pred_train)\n",
        "baseline_poisson_deviance = mean_poisson_deviance(y_train, naive_pred_train)\n",
        "print('The mean absolute error of our naive estimator is:', baseline_MAE_train)\n",
        "print('The baseline Poisson deviance is:', baseline_poisson_deviance)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The mean absolute error of our naive estimator is: 0.5034843933841647\n",
            "The baseline Poisson deviance is: 0.9052658453895543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pRE0GIoQ8xR"
      },
      "source": [
        "model_xg = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(strategy = 'median'),\n",
        "    XGBRegressor(objective = 'count:poisson')\n",
        ")\n",
        "\n",
        "model_xg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RibZpFWbLg1Q"
      },
      "source": [
        "# hyperparamter tuning the XGBoost model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "WL1DvccAeF6M",
        "outputId": "80009838-4703-4a5b-eb92-881a289a8428"
      },
      "source": [
        "# creating another model using the QuantileRandomForestRegressor from scikit garden\n",
        "\n",
        "model_rfq = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(strategy = 'median'),\n",
        "    RandomForestQuantileRegressor()\n",
        ")\n",
        "\n",
        "model_rfq.fit(X_train, y_train);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dce740cb6cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating another model using the QuantileRandomForestRegressor from scikit garden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model_rfq = make_pipeline(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_pipeline' is not defined"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dce740cb6cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# creating another model using the QuantileRandomForestRegressor from scikit garden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model_rfq = make_pipeline(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'median'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'make_pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRgycTojK_jl",
        "outputId": "4173b4be-2c84-416d-ea98-721dcf50e820"
      },
      "source": [
        "model_MAE = mean_absolute_error(y_val, model_xg.predict(X_val))\n",
        "model_rsquared = model_xg.score(X_val, y_val)\n",
        "model_poisson_deviance = mean_poisson_deviance(y_val, model_xg.predict(X_val))\n",
        "print('The MAE of my first model is:', model_MAE)\n",
        "print('The R Squared of my first model is:', model_rsquared)\n",
        "print('The model Poisson deviance is:', model_poisson_deviance)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The MAE of my first model is: 0.4524271821130668\n",
            "The R Squared of my first model is: 0.07900258547127381\n",
            "The model Poisson deviance is: 0.8182386347929967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIRkYFPvLmEN"
      },
      "source": [
        "features = model_xg.named_steps['ordinalencoder'].get_feature_names()\n",
        "feature_importances = model_xg.named_steps['xgbregressor'].feature_importances_\n",
        "\n",
        "feature_series = pd.Series(feature_importances, index = features).sort_values()\n",
        "\n",
        "feature_series.plot.barh()\n",
        "plt.title('Feature Importances for the XGB Regressor Model')\n",
        "plt.xlabel('Importances')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc91iTv2OhVf"
      },
      "source": [
        "perm_imp_regressor = permutation_importance(model_xg, X_val, y_val, n_repeats = 5)\n",
        "\n",
        "perm_dict = {\n",
        "    'importance_mean' : perm_imp_regressor['importances_mean'],\n",
        "    'importance_std' : perm_imp_regressor['importances_std']\n",
        "}\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7CfD4p4PISt"
      },
      "source": [
        "perm_df = pd.DataFrame(perm_dict, index = features)\n",
        "perm_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNGY5BJ9blqQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}